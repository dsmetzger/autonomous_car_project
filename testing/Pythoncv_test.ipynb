{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#idk diference between cv and cv2. I think cv2 has class functionality\n",
    "#import cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#library needed on beaglebone\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_480p(file):\n",
    "    img=cv2.imread(file)\n",
    "    img=cv2.resize(img,(640,480))\n",
    "    gray_img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img,gray_img\n",
    "def get_cut_480p(file):\n",
    "    img=cv2.imread(file)\n",
    "    img1=img[320:,:]\n",
    "    gray_img=cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    return img1,gray_img\n",
    "def get_360p(file):\n",
    "    img=cv2.imread(file)\n",
    "    img=cv2.resize(img,(320,240))\n",
    "    gray_img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img,gray_img\n",
    "def display(img):\n",
    "    try:\n",
    "        b,g,r = cv2.split(img)\n",
    "        img2 = cv2.merge([r,g,b])\n",
    "        imgplot = plt.imshow(img)\n",
    "        plt.show()\n",
    "    except:    \n",
    "        imgplot = plt.imshow(img,cmap='gray')\n",
    "        plt.show()\n",
    "def hough_trans(img,gray,can_min=50,can_max=350,vote=100,plot_canny=0,plot_img=0):\n",
    "    t1 = time.time()\n",
    "    edges = cv2.Canny(gray,can_min,can_max,apertureSize = 3)\n",
    "    t2 = time.time()\n",
    "    lines = cv2.HoughLines(edges,1,np.pi/180,vote)\n",
    "    t3 = time.time()\n",
    "    print 'canny',t2 - t1\n",
    "    print 'hough',t3 - t2\n",
    "    if plot_canny==1:\n",
    "                display(edges)\n",
    "    #print lines\n",
    "    if plot_img==1:\n",
    "        try:\n",
    "            for rho,theta in lines[0]:\n",
    "                print rho,theta\n",
    "                a = np.cos(theta)\n",
    "                b = np.sin(theta)\n",
    "                x0 = a*rho\n",
    "                y0 = b*rho\n",
    "                x1 = int(x0 + 1000*(-b))\n",
    "                y1 = int(y0 + 1000*(a))\n",
    "                x2 = int(x0 - 1000*(-b))\n",
    "                y2 = int(y0 - 1000*(a))\n",
    "                cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "            display(img)\n",
    "        except:\n",
    "            print('could not plot')\n",
    "    else:\n",
    "        try:\n",
    "            return len(lines[0])\n",
    "        except:\n",
    "            return 0\n",
    "def hough_transp(img,gray,can_min=150,can_max=300,vote=150,\n",
    "                 minLineLength = 20,maxLineGap = 15,plot_canny=0,plot_img=0):\n",
    "    #hough that uses less test points, less computations\n",
    "    t1 = time.time()\n",
    "    edges = cv2.Canny(gray,can_min,can_max,apertureSize = 3)\n",
    "    t2 = time.time()\n",
    "    lines = cv2.HoughLinesP(edges,1,np.pi/180,vote,minLineLength,maxLineGap)\n",
    "    t3 = time.time()\n",
    "    print 'canny',t2 - t1\n",
    "    print 'hough',t3 - t2\n",
    "    if plot_canny==1:\n",
    "        display(edges)\n",
    "    #print lines\n",
    "    if plot_img==1:\n",
    "        try:\n",
    "            for x1,y1,x2,y2 in lines[0]:\n",
    "                cv2.line(img,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "            display(img)\n",
    "        except:\n",
    "            print('could not plot')\n",
    "    else:\n",
    "        try:\n",
    "            return len(lines[0])\n",
    "        except:\n",
    "            return 0\n",
    "def hough_trans_blur(img,gray,can_min=50,can_max=350,vote=100,plot_canny=0):\n",
    "    t1 = time.time()\n",
    "    blur = cv2.blur(gray,(2,2))\n",
    "    t2 = time.time()\n",
    "    edges = cv2.Canny(gray,can_min,can_max,apertureSize = 3)\n",
    "    t3 = time.time()\n",
    "    lines = cv2.HoughLines(edges,1,np.pi/180,vote)\n",
    "    t4 = time.time()\n",
    "    print 'blur', t2 - t1\n",
    "    print 'canny',t3 - t2\n",
    "    print 'hough',t4 - t3\n",
    "    #print lines\n",
    "    for rho,theta in lines[0]:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*rho\n",
    "        y0 = b*rho\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "        cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "    if plot_canny==1:\n",
    "        display(edges)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img1,gray=get_480p('2-knee.jpg')\n",
    "display(img1)\n",
    "#blur = cv2.bilateralFilter(gray,9,75,75)\n",
    "#display(blur)\n",
    "hough_trans(img1,gray,vote=220,can_min=150,can_max=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canny 0.0159690380096\n",
      "hough 0.0594630241394\n",
      "canny 0.00412583351135\n",
      "hough 0.039165019989\n",
      "canny 0.00395011901855\n",
      "hough 0.0327048301697\n",
      "canny 0.00391983985901\n",
      "hough 0.0439879894257\n",
      "canny 0.00376510620117\n",
      "hough 0.031387090683\n",
      "canny 0.0038731098175\n",
      "hough 0.0439279079437\n",
      "canny 0.00368499755859\n",
      "hough 0.0306220054626\n",
      "canny 0.00390386581421\n",
      "hough 0.034784078598\n",
      "canny 0.00378108024597\n",
      "hough 0.0309338569641\n",
      "canny 0.00367498397827\n",
      "hough 0.0439021587372\n",
      "canny 0.00378179550171\n",
      "hough 0.0324721336365\n",
      "canny 0.00373196601868\n",
      "hough 0.0437178611755\n",
      "canny 0.00358510017395\n",
      "hough 0.0315179824829\n",
      "canny 0.00372219085693\n",
      "hough 0.0437188148499\n",
      "canny 0.00405406951904\n",
      "hough 0.0314509868622\n",
      "canny 0.00389504432678\n",
      "hough 0.0443139076233\n",
      "canny 0.00359606742859\n",
      "hough 0.031476020813\n",
      "canny 0.00388598442078\n",
      "hough 0.0446491241455\n",
      "canny 0.00377607345581\n",
      "hough 0.0326941013336\n",
      "canny 0.00389003753662\n",
      "hough 0.0436959266663\n",
      "canny 0.00379800796509\n",
      "hough 0.0311269760132\n",
      "157.0 1.65806\n",
      "153.0 1.65806\n",
      "488.0 0.890118\n",
      "494.0 0.872665\n",
      "500.0 0.820305\n",
      "-110.0 2.35619\n",
      "-91.0 2.35619\n",
      "-112.0 2.35619\n",
      "46.0 1.69297\n",
      "296.0 1.16937\n",
      "-139.0 2.35619\n",
      "-93.0 2.35619\n",
      "-95.0 2.35619\n",
      "-127.0 2.35619\n",
      "64.0 1.65806\n",
      "44.0 1.72788\n",
      "-120.0 2.35619\n",
      "-98.0 2.35619\n",
      "[200, 194.75, 200.75, 195.5, 200.75, 195.5, 200.75, 195.5, 200.75, 195.5, 200.75, 195.5, 200.75, 195.5, 200.75, 195.5, 200.75, 195.5, 200.75, 195.5, 200.75]\n"
     ]
    }
   ],
   "source": [
    "#iterating hough\n",
    "img1,gray=get_480p('1-a.jpg')\n",
    "#img1,gray=get_360p('2-knee.jpg')\n",
    "display(img1)\n",
    "it_vote=200\n",
    "lvote=[it_vote]\n",
    "lln=[]\n",
    "mu=.75\n",
    "n_lines=25\n",
    "for x in range(0,20):\n",
    "    ln=hough_trans(img1,gray,vote=int(it_vote),can_min=200,can_max=250)\n",
    "    lln.append(ln)\n",
    "    fixed=n_lines-ln\n",
    "    #iterate\n",
    "    it_vote=it_vote-mu*fixed\n",
    "    lvote.append(it_vote)\n",
    "ln=hough_trans(img1,gray,vote=int(it_vote),can_min=200,can_max=250,plot_canny=1,plot_img=1)\n",
    "print(lvote)\n",
    "plt.figure(1)\n",
    "plt.plot(lvote)\n",
    "plt.ylabel('Vote')\n",
    "plt.xlabel('Iteration')\n",
    "plt.figure(2)\n",
    "plt.plot(lln)\n",
    "plt.ylabel('Number of lines')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canny 0.0276520252228\n",
      "hough 0.111211061478\n",
      "canny 0.0162751674652\n",
      "hough 0.102469921112\n",
      "canny 0.0204839706421\n",
      "hough 0.10874080658\n",
      "canny 0.0201292037964\n",
      "hough 0.104791879654\n",
      "canny 0.0171658992767\n",
      "hough 0.103147029877\n",
      "canny 0.0166850090027\n",
      "hough 0.1023209095\n",
      "canny 0.0170180797577\n",
      "hough 0.102043867111\n",
      "canny 0.0168590545654\n",
      "hough 0.102880954742\n",
      "canny 0.0166149139404\n",
      "hough 0.109311103821\n",
      "canny 0.0163550376892\n",
      "hough 0.101863861084\n",
      "canny 0.0157868862152\n",
      "hough 0.103569030762\n",
      "canny 0.0160369873047\n",
      "hough 0.114208221436\n",
      "canny 0.016685962677\n",
      "hough 0.112518072128\n",
      "canny 0.0167601108551\n",
      "hough 0.104924917221\n",
      "canny 0.016802072525\n",
      "hough 0.103017807007\n",
      "canny 0.0168080329895\n",
      "hough 0.103849887848\n",
      "canny 0.016487121582\n",
      "hough 0.103917837143\n",
      "canny 0.0166800022125\n",
      "hough 0.102876901627\n",
      "canny 0.0167369842529\n",
      "hough 0.105627059937\n",
      "canny 0.0167851448059\n",
      "hough 0.102952003479\n",
      "canny 0.0166349411011\n",
      "hough 0.105222940445\n",
      "could not plot\n",
      "[200, 1334.45, 1333.55, 1332.6499999999999, 1331.7499999999998, 1330.8499999999997, 1329.9499999999996, 1329.0499999999995, 1328.1499999999994, 1327.2499999999993, 1326.3499999999992, 1325.4499999999991, 1324.549999999999, 1323.649999999999, 1322.7499999999989, 1321.8499999999988, 1320.9499999999987, 1320.0499999999986, 1319.1499999999985, 1318.2499999999984, 1317.3499999999983]\n"
     ]
    }
   ],
   "source": [
    "img,gray=get_cut_480p('4-knee.jpg')\n",
    "display(img)\n",
    "it_vote=200\n",
    "lvote=[it_vote]\n",
    "lln=[]\n",
    "mu=.45\n",
    "n_lines=2\n",
    "for x in range(0,20):\n",
    "    ln=hough_trans(img1,gray,vote=int(it_vote),can_min=200,can_max=250)\n",
    "    lln.append(ln)\n",
    "    fixed=n_lines-ln\n",
    "    #iterate\n",
    "    it_vote=it_vote-mu*fixed\n",
    "    lvote.append(it_vote)\n",
    "ln=hough_trans(img1,gray,vote=int(it_vote),can_min=200,can_max=250,plot_canny=1,plot_img=1)\n",
    "print(lvote)\n",
    "plt.figure(1)\n",
    "plt.plot(lvote)\n",
    "plt.ylabel('Vote')\n",
    "plt.xlabel('Iteration')\n",
    "plt.figure(2)\n",
    "plt.plot(lln)\n",
    "plt.ylabel('Number of lines')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#circles\n",
    "img,gray=get_480p('1-a.jpg')\n",
    "display(gray)\n",
    "blur = cv2.medianBlur(gray,5)\n",
    "display(blur)\n",
    "circles = cv2.HoughCircles(blur,3,30,3)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(gray,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    # draw the center of the circle\n",
    "    cv2.circle(gray,(i[0],i[1]),2,(0,0,255),3)\n",
    "display(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get low image resolution or take midsection of high res.\n",
    "#blur, use the bit operator to only output where the sidewalk is, travel on right side.\n",
    "#in forest area use the high intensity light as a sign of the sidewalk being there\n",
    "#perhaps make algorithim to detect white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#try to use the averaging filters to get the whole concrete slab\n",
    "img,gray=get_480p('8.jpg')\n",
    "blur = cv2.blur(gray,(2,2))\n",
    "display(blur)\n",
    "hough_trans(img,gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use bilateral filtering to remove texture(concrete) but is cpu intensive. \n",
    "img,gray=get_480p('8.jpg')\n",
    "blur = cv2.bilateralFilter(gray,9,75,75)\n",
    "display(blur)\n",
    "hough_trans(img,gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#individual colors\n",
    "img,gray=get_480p('4-knee.jpg')\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "lower_blue = np.array([50,50,110])\n",
    "upper_blue = np.array([255,255,130])\n",
    "mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    " # Bitwise-AND mask and original image\n",
    "res = cv2.bitwise_and(img,img, mask= mask)\n",
    "display(img)\n",
    "display(mask)\n",
    "display(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img=cv2.imread('4-knee.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#returns (height, width, pixel element number)\n",
    "height, width, pixel=img.shape\n",
    "print img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img2 = img[280:340, 330:390]#take section of the picture\n",
    "img[273:333, 100:160] = img2#put that section on original picutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b,g,r = cv2.split(img)#full splitting into colors\n",
    "b = img[:,:,0]#individual blue color\n",
    "imgplot = plt.imshow(b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grayscale\n",
    "gray_img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "imgplot = plt.imshow(gray_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HSV\n",
    "hsv_img=cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "imgplot = plt.imshow(hsv_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print img[0,0]\n",
    "print gray_img[0,0]\n",
    "print hsv_img[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#capture video\n",
    "cap = cv2.VideoCapture(0)\n",
    "while 1:\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:#check if cap.read() returned frame\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        display(gray)\n",
    "        #image recognition code here\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#canny edge detection\n",
    "img = cv2.imread('4-knee.jpg',0)\n",
    "edges = cv2.Canny(img,100,200)\n",
    "\n",
    "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('1-a.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,160,300,apertureSize = 3)\n",
    "lines = cv2.HoughLines(edges,1,np.pi/180,200)\n",
    "#print lines\n",
    "for rho,theta in lines[0]:\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "\n",
    "plt.subplot(121),plt.imshow(edges,cmap = 'gray')\n",
    "plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "#plt.imshow(img,cmap='gray')\n",
    "plt.show()\n",
    "#cv2.imwrite('houghlines1.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hough that uses less test points, less computations\n",
    "img = cv2.imread('4-knee.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "minLineLength = 100\n",
    "maxLineGap = 20\n",
    "lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength,maxLineGap)\n",
    "#print lines\n",
    "for x1,y1,x2,y2 in lines[0]:\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "plt.subplot(121),plt.imshow(edges,cmap = 'gray')\n",
    "plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "plt.show()\n",
    "#cv2.imwrite('houghlines2.jpg',img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
