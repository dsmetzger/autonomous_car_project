{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#idk diference between cv and cv2. I think cv2 has class functionality\n",
    "#import cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#library needed on beaglebone\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_480p(file):\n",
    "    img=cv2.imread(file)\n",
    "    img=cv2.resize(img,(640,480))\n",
    "    gray_img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img,gray_img\n",
    "def get_cut_480p(file):\n",
    "    img=cv2.imread(file)\n",
    "    img1=img[320:,:]\n",
    "    gray_img=cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    return img1,gray_img\n",
    "def get_360p(file):\n",
    "    img=cv2.imread(file)\n",
    "    img=cv2.resize(img,(320,240))\n",
    "    gray_img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img,gray_img\n",
    "def display(img):\n",
    "    try:\n",
    "        b,g,r = cv2.split(img)\n",
    "        img2 = cv2.merge([r,g,b])\n",
    "        imgplot = plt.imshow(img)\n",
    "        plt.show()\n",
    "    except:    \n",
    "        imgplot = plt.imshow(img,cmap='gray')\n",
    "        plt.show()\n",
    "def hough_trans(img,gray,can_min=50,can_max=350,vote=100,plot_canny=0):\n",
    "    t1 = time.time()\n",
    "    edges = cv2.Canny(gray,can_min,can_max,apertureSize = 3)\n",
    "    display(edges)\n",
    "    t2 = time.time()\n",
    "    lines = cv2.HoughLines(edges,1,np.pi/180,125)\n",
    "    t3 = time.time()\n",
    "    print 'canny',t2 - t1\n",
    "    print 'hough',t3 - t2\n",
    "    #print lines\n",
    "    print lines\n",
    "    for rho,theta in lines[0]:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*rho\n",
    "        y0 = b*rho\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "        cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "    if plot_canny==1:\n",
    "        display(edges)\n",
    "    display(img)\n",
    "def hough_transp(img,gray,can_min=50,can_max=350,vote=100,minLineLength = 100,maxLineGap = 20,plot_canny=0):\n",
    "    #hough that uses less test points, less computations\n",
    "    img = cv2.imread('4-knee.jpg')\n",
    "    t1 = time.time()\n",
    "    edges = cv2.Canny(gray,can_min,can_max,apertureSize = 3)\n",
    "    t2 = time.time()\n",
    "    lines = cv2.HoughLinesP(edges,1,np.pi/180,vote,minLineLength,maxLineGap)\n",
    "    t3 = time.time()\n",
    "    print 'canny',t2 - t1\n",
    "    print 'hough',t3 - t2\n",
    "    #plot lines\n",
    "    for x1,y1,x2,y2 in lines[0]:\n",
    "        cv2.line(img,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "    if plot_canny==1:\n",
    "        display(edges)\n",
    "    display(img)\n",
    "def hough_trans_blur(img,gray,can_min=50,can_max=350,vote=100,plot_canny=0):\n",
    "    t1 = time.time()\n",
    "    blur = cv2.blur(gray,(2,2))\n",
    "    t2 = time.time()\n",
    "    edges = cv2.Canny(gray,can_min,can_max,apertureSize = 3)\n",
    "    t3 = time.time()\n",
    "    lines = cv2.HoughLines(edges,1,np.pi/180,vote)\n",
    "    t4 = time.time()\n",
    "    print 'blur', t2 - t1\n",
    "    print 'canny',t3 - t2\n",
    "    print 'hough',t4 - t3\n",
    "    #print lines\n",
    "    for rho,theta in lines[0]:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*rho\n",
    "        y0 = b*rho\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "        cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "    if plot_canny==1:\n",
    "        display(edges)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img1,gray=get_cut_480p('2-knee.jpg')\n",
    "display(gray)\n",
    "blur = cv2.bilateralFilter(gray,9,75,75)\n",
    "display(blur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canny 10.0288329124\n",
      "hough 0.02481508255\n",
      "[[[ 523.            1.62315619]\n",
      "  [   3.            1.57079637]\n",
      "  [  10.            1.57079637]\n",
      "  [   7.            1.57079637]\n",
      "  [-878.            2.60054064]\n",
      "  [  -8.            1.58824956]\n",
      "  [ -10.            1.58824956]\n",
      "  [  17.            1.57079637]\n",
      "  [ -32.            1.60570288]\n",
      "  [  -4.            1.58824956]\n",
      "  [  73.            1.53588974]\n",
      "  [  39.            1.55334306]\n",
      "  [ -35.            1.60570288]\n",
      "  [ -12.            1.58824956]\n",
      "  [  14.            1.57079637]\n",
      "  [ -16.            1.58824956]\n",
      "  [ -18.            1.58824956]\n",
      "  [ -74.            1.6406095 ]\n",
      "  [  12.            1.57079637]\n",
      "  [  22.            1.57079637]\n",
      "  [  72.            1.43116999]\n",
      "  [  37.            1.55334306]\n",
      "  [  61.            1.46607661]\n",
      "  [ -37.            1.60570288]\n",
      "  [-860.            2.58308721]\n",
      "  [ -54.            1.62315619]\n",
      "  [  70.            1.53588974]\n",
      "  [ 539.            1.60570288]\n",
      "  [ -40.            1.60570288]\n",
      "  [  67.            1.53588974]\n",
      "  [  33.            1.55334306]\n",
      "  [ -21.            1.58824956]\n",
      "  [ -24.            1.60570288]\n",
      "  [  99.            1.51843643]\n",
      "  [ -57.            1.62315619]\n",
      "  [ -88.            1.6406095 ]\n",
      "  [ -90.            1.6406095 ]\n",
      "  [  48.            1.55334306]\n",
      "  [ -60.            1.62315619]\n",
      "  [ -62.            1.62315619]\n",
      "  [  31.            1.55334306]\n",
      "  [  76.            1.53588974]\n",
      "  [ 101.            1.51843643]\n",
      "  [-113.            1.65806282]\n",
      "  [ -43.            1.60570288]\n",
      "  [  28.            1.55334306]\n",
      "  [ 529.            1.60570288]\n",
      "  [  45.            1.55334306]\n",
      "  [ -67.            1.62315619]\n",
      "  [-141.            1.67551613]\n",
      "  [-900.            2.61799383]\n",
      "  [ -85.            1.6406095 ]\n",
      "  [ -26.            1.60570288]\n",
      "  [ -46.            1.60570288]\n",
      "  [-145.            1.67551613]\n",
      "  [ -81.            1.6406095 ]\n",
      "  [  56.            1.55334306]\n",
      "  [ -23.            1.58824956]\n",
      "  [-110.            1.65806282]\n",
      "  [ -69.            1.62315619]\n",
      "  [  58.            1.53588974]\n",
      "  [-894.            2.61799383]\n",
      "  [ -65.            1.62315619]\n",
      "  [-120.            1.65806282]\n",
      "  [ -93.            1.6406095 ]\n",
      "  [  60.            1.53588974]\n",
      "  [-117.            1.65806282]\n",
      "  [ -45.            1.62315619]\n",
      "  [ -71.            1.6406095 ]\n",
      "  [ -78.            1.6406095 ]\n",
      "  [ -72.            1.62315619]\n",
      "  [ 105.            1.51843643]\n",
      "  [  26.            1.57079637]\n",
      "  [-137.            1.67551613]\n",
      "  [  53.            1.55334306]\n",
      "  [ -49.            1.62315619]\n",
      "  [  50.            1.55334306]\n",
      "  [  81.            1.53588974]\n",
      "  [-115.            1.65806282]\n",
      "  [  79.            1.53588974]\n",
      "  [ -95.            1.6406095 ]\n",
      "  [  77.            1.55334306]\n",
      "  [-178.            1.69296932]\n",
      "  [ 125.            1.50098312]\n",
      "  [  62.            1.55334306]\n",
      "  [-168.            1.69296932]\n",
      "  [ 120.            1.51843643]\n",
      "  [-139.            1.67551613]\n",
      "  [ 164.            1.62315619]\n",
      "  [-105.            1.65806282]\n",
      "  [-125.            1.65806282]\n",
      "  [-180.            1.69296932]\n",
      "  [ 131.            1.51843643]\n",
      "  [  68.            1.4486233 ]]]\n"
     ]
    }
   ],
   "source": [
    "hough_trans(img1,blur,vote=150,can_min=50,can_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#try only the area directly in front of the robot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get low image resolution or take midsection of high res.\n",
    "#blur, use the bit operator to only output where the sidewalk is, travel on right side.\n",
    "#perhaps fill in bits of data. \n",
    "#in forest area use the high intensity light as a sign of the sidewalk being there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#try to use the averaging filters to get the whole concrete slab\n",
    "img,gray=get_480p('8.jpg')\n",
    "blur = cv2.blur(gray,(2,2))\n",
    "display(blur)\n",
    "hough_trans(img,gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use bilateral filtering to remove texture(concrete) but is cpu intensive. \n",
    "img,gray=get_480p('8.jpg')\n",
    "blur = cv2.bilateralFilter(gray,9,75,75)\n",
    "display(blur)\n",
    "hough_trans(img,gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for tree area use just the green element, anything in between high amounts of green is sidewalk.\n",
    "#use the binary operators to set up this mappying.\n",
    "img,gray=get_480p('4-knee.jpg')\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "lower_blue = np.array([50,50,110])\n",
    "upper_blue = np.array([255,255,130])\n",
    "mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    " # Bitwise-AND mask and original image\n",
    "res = cv2.bitwise_and(img,img, mask= mask)\n",
    "display(img)\n",
    "display(mask)\n",
    "display(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img=cv2.imread('4-knee.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#returns (height, width, pixel element number)\n",
    "height, width, pixel=img.shape\n",
    "print img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img2 = img[280:340, 330:390]#take section of the picture\n",
    "img[273:333, 100:160] = img2#put that section on original picutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b,g,r = cv2.split(img)#full splitting into colors\n",
    "b = img[:,:,0]#individual blue color\n",
    "imgplot = plt.imshow(b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grayscale\n",
    "gray_img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "imgplot = plt.imshow(gray_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HSV\n",
    "hsv_img=cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "imgplot = plt.imshow(hsv_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print img[0,0]\n",
    "print gray_img[0,0]\n",
    "print hsv_img[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#capture video\n",
    "cap = cv2.VideoCapture(0)\n",
    "while 1:\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:#check if cap.read() returned frame\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        display(gray)\n",
    "        #image recognition code here\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#canny edge detection\n",
    "img = cv2.imread('4-knee.jpg',0)\n",
    "edges = cv2.Canny(img,100,200)\n",
    "\n",
    "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('1-a.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,160,300,apertureSize = 3)\n",
    "lines = cv2.HoughLines(edges,1,np.pi/180,200)\n",
    "#print lines\n",
    "for rho,theta in lines[0]:\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "\n",
    "plt.subplot(121),plt.imshow(edges,cmap = 'gray')\n",
    "plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "#plt.imshow(img,cmap='gray')\n",
    "plt.show()\n",
    "#cv2.imwrite('houghlines1.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hough that uses less test points, less computations\n",
    "img = cv2.imread('4-knee.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "minLineLength = 100\n",
    "maxLineGap = 20\n",
    "lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength,maxLineGap)\n",
    "#print lines\n",
    "for x1,y1,x2,y2 in lines[0]:\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "plt.subplot(121),plt.imshow(edges,cmap = 'gray')\n",
    "plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "plt.show()\n",
    "#cv2.imwrite('houghlines2.jpg',img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
