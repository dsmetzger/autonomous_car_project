{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#idk diference between cv and cv2. I think cv2 has class functionality\n",
    "#import cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#library needed on beaglebone\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_480p(file):\n",
    "    img=cv2.imread(file)\n",
    "    img=cv2.resize(img,(640,480))\n",
    "    gray_img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img,gray_img\n",
    "def get_cut_480p(file,xcut=[0,640],ycut=[0,480]):\n",
    "    img=cv2.imread(file)\n",
    "    img=cv2.resize(img,(640,480))\n",
    "    img1=img[ycut[0]:ycut[1],xcut[0]:xcut[1]]\n",
    "    gray_img=cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    return img,img1,gray_img\n",
    "def get_360p(file):\n",
    "    img=cv2.imread(file)\n",
    "    img=cv2.resize(img,(320,240))\n",
    "    gray_img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img,gray_img\n",
    "def display(img):\n",
    "    try:\n",
    "        b,g,r = cv2.split(img)\n",
    "        img2 = cv2.merge([b,g,r])\n",
    "        imgplot = plt.imshow(img)\n",
    "        plt.show()\n",
    "    except:    \n",
    "        imgplot = plt.imshow(img,cmap='gray')\n",
    "        plt.show()\n",
    "def hough_trans(img,gray,can_min=50,can_max=350,vote=100,plot_canny=0,plot_img=0):\n",
    "    t1 = time.time()\n",
    "    edges = cv2.Canny(gray,can_min,can_max,apertureSize = 3)\n",
    "    t2 = time.time()\n",
    "    lines = cv2.HoughLines(edges,1,np.pi/180,vote)\n",
    "    t3 = time.time()\n",
    "    print 'canny',t2 - t1\n",
    "    print 'hough',t3 - t2\n",
    "    if plot_canny==1:\n",
    "                display(edges)\n",
    "    #print lines\n",
    "    if plot_img==1:\n",
    "        try:\n",
    "            for rho,theta in lines[0]:\n",
    "                print rho,theta\n",
    "                a = np.cos(theta)\n",
    "                b = np.sin(theta)\n",
    "                x0 = a*rho\n",
    "                y0 = b*rho\n",
    "                x1 = int(x0 + 1000*(-b))\n",
    "                y1 = int(y0 + 1000*(a))\n",
    "                x2 = int(x0 - 1000*(-b))\n",
    "                y2 = int(y0 - 1000*(a))\n",
    "                cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "            display(img)\n",
    "        except:\n",
    "            print('could not plot')\n",
    "    else:\n",
    "        try:\n",
    "            return len(lines[0])\n",
    "        except:\n",
    "            return 0\n",
    "def hough_transp(img,gray,can_min=150,can_max=300,vote=150,\n",
    "                 minLineLength = 20,maxLineGap = 15,plot_canny=0,plot_img=0):\n",
    "    #hough that uses less test points, less computations\n",
    "    t1 = time.time()\n",
    "    edges = cv2.Canny(gray,can_min,can_max,apertureSize = 3)\n",
    "    t2 = time.time()\n",
    "    lines = cv2.HoughLinesP(edges,1,np.pi/180,vote,minLineLength,maxLineGap)\n",
    "    t3 = time.time()\n",
    "    print 'canny',t2 - t1\n",
    "    print 'hough',t3 - t2\n",
    "    if plot_canny==1:\n",
    "        display(edges)\n",
    "    #print lines\n",
    "    if plot_img==1:\n",
    "        try:\n",
    "            for x1,y1,x2,y2 in lines[0]:\n",
    "                cv2.line(img,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "            display(img)\n",
    "        except:\n",
    "            print('could not plot')\n",
    "    else:\n",
    "        try:\n",
    "            return len(lines[0])\n",
    "        except:\n",
    "            return 0\n",
    "def hough_trans_blur(img,gray,can_min=50,can_max=350,vote=100,plot_canny=0):\n",
    "    t1 = time.time()\n",
    "    blur = cv2.blur(gray,(2,2))\n",
    "    t2 = time.time()\n",
    "    edges = cv2.Canny(gray,can_min,can_max,apertureSize = 3)\n",
    "    t3 = time.time()\n",
    "    lines = cv2.HoughLines(edges,1,np.pi/180,vote)\n",
    "    t4 = time.time()\n",
    "    print 'blur', t2 - t1\n",
    "    print 'canny',t3 - t2\n",
    "    print 'hough',t4 - t3\n",
    "    #print lines\n",
    "    for rho,theta in lines[0]:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*rho\n",
    "        y0 = b*rho\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "        cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "    if plot_canny==1:\n",
    "        display(edges)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#look at white concrete\n",
    "img,reimg,gray=get_cut_480p('9.jpg',xcut=[400,470],ycut=[420,480])#get img, roi image, and gray cut img\n",
    "#img,reimg,gray=get_cut_480p('1.jpg',xcut=[600,640],ycut=[400,480])#get img, roi image, and gray cut img\n",
    "display(reimg)\n",
    "b,g,r = cv2.split(reimg)\n",
    "print reimg\n",
    "#hsv to detect white?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:10: RuntimeWarning: overflow encountered in ubyte_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create green pointers on sidewalk\n",
    "img,reimg,gray=get_cut_480p('9.jpg',xcut=[0,640],ycut=[0,480])#get img, roi image, and gray cut img\n",
    "#display(reimg)\n",
    "#b,g,r = cv2.split(reimg)\n",
    "i=0;\n",
    "for x in range(0,640,10):#\n",
    "    for y in range(0,480,10):\n",
    "        bgr=reimg[y,x]\n",
    "        #also take the difference between g and r? if too high means its not white\n",
    "        if bgr[0]*1.2>(bgr[1]+bgr[2])/2:#check if white with a bit more of blue\n",
    "        #if abs(bgr[1]-bgr[2])<15:\n",
    "            i+=1\n",
    "            #draw where true\n",
    "            for x1 in range(-2,3):\n",
    "                for y1 in range(-2,3):\n",
    "                    reimg[y+y1,x+x1]=[0,200,255]\n",
    "print i\n",
    "#hsv to detect white?\n",
    "display(reimg)\n",
    "cv2.imwrite('9_white_detection.jpg', reimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 55  71  77]\n",
      "  [ 56  72  78]\n",
      "  [ 57  73  79]\n",
      "  ..., \n",
      "  [ 72  91  94]\n",
      "  [255 200   0]\n",
      "  [255 200   0]]\n",
      "\n",
      " [[ 52  68  74]\n",
      "  [ 53  69  75]\n",
      "  [ 52  68  74]\n",
      "  ..., \n",
      "  [ 78  97 100]\n",
      "  [255 200   0]\n",
      "  [255 200   0]]\n",
      "\n",
      " [[ 52  69  73]\n",
      "  [ 53  69  75]\n",
      "  [ 55  71  77]\n",
      "  ..., \n",
      "  [ 47  66  69]\n",
      "  [255 200   0]\n",
      "  [255 200   0]]\n",
      "\n",
      " ..., \n",
      " [[ 61  80  84]\n",
      "  [ 67  86  89]\n",
      "  [ 76  95  98]\n",
      "  ..., \n",
      "  [ 66  85  88]\n",
      "  [ 69  88  91]\n",
      "  [ 77  96  99]]\n",
      "\n",
      " [[ 62  79  84]\n",
      "  [ 67  86  89]\n",
      "  [ 70  89  92]\n",
      "  ..., \n",
      "  [ 57  76  79]\n",
      "  [ 66  85  88]\n",
      "  [ 82 101 104]]\n",
      "\n",
      " [[ 60  76  82]\n",
      "  [ 67  86  89]\n",
      "  [ 70  89  92]\n",
      "  ..., \n",
      "  [ 73  92  96]\n",
      "  [ 74  93  96]\n",
      "  [ 78  97 100]]]\n"
     ]
    }
   ],
   "source": [
    "print reimg[380:420,280:300]\n",
    "display(reimg[380:420,280:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find corners\n",
    "img,gray=get_480p('1.jpg')\n",
    "\n",
    "#gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "\n",
    "#result is dilated for marking the corners, not important\n",
    "dst = cv2.dilate(dst,None)\n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img[dst>0.01*dst.max()]=[0,0,255]\n",
    "\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canny 0.0295388698578\n",
      "hough 0.0421450138092\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img1,gray=get_480p('2-knee.jpg')\n",
    "display(img1)\n",
    "#blur = cv2.bilateralFilter(gray,9,75,75)\n",
    "#display(blur)\n",
    "hough_trans(img1,gray,vote=220,can_min=150,can_max=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "canny 0.00276684761047\n",
      "hough 0.0175821781158\n",
      "canny 0.0019679069519\n",
      "hough 0.0138740539551\n",
      "canny 0.00164484977722\n",
      "hough 0.0108580589294\n",
      "canny 0.00142383575439\n",
      "hough 0.0124080181122\n",
      "canny 0.00128293037415\n",
      "hough 0.00853610038757\n",
      "canny 0.00126194953918\n",
      "hough 0.00887513160706\n",
      "51.0 1.62316\n",
      "53.0 1.62316\n",
      "-26.0 3.00197\n",
      "50.0 1.64061\n",
      "188.0 1.6057\n",
      "3.0 1.62316\n",
      "191.0 1.6057\n",
      "5.0 1.62316\n",
      "-23.0 2.98451\n",
      "-24.0 3.00197\n",
      "[100, 107.5, 113.5, 118.75, 122.5, 126.25]\n"
     ]
    }
   ],
   "source": [
    "#iterating hough\n",
    "img,reimg,gray=get_cut_480p('1.jpg',xcut=[240,520],ycut=[200,480])#get img, roi image, and gray cut img\n",
    "display(reimg)\n",
    "#img1,gray=get_360p('2-knee.jpg')\n",
    "it_vote=100\n",
    "lvote=[it_vote]\n",
    "lln=[]\n",
    "mu=.75\n",
    "n_lines=5\n",
    "for x in range(0,5):\n",
    "    ln=hough_trans(reimg,gray,vote=int(it_vote),can_min=200,can_max=250)\n",
    "    lln.append(ln)\n",
    "    fixed=n_lines-ln\n",
    "    #iterate\n",
    "    it_vote=it_vote-mu*fixed\n",
    "    lvote.append(it_vote)\n",
    "ln=hough_trans(reimg,gray,vote=int(it_vote),can_min=200,can_max=250,plot_canny=1,plot_img=1)\n",
    "print(lvote)\n",
    "plt.figure(1)\n",
    "plt.plot(lvote)\n",
    "plt.ylabel('Vote')\n",
    "plt.xlabel('Iteration')\n",
    "plt.figure(2)\n",
    "plt.plot(lln)\n",
    "plt.ylabel('Number of lines')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-d0ac459a4583>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_cut_480p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'4-knee.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mit_vote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlvote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mit_vote\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlln\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack"
     ]
    }
   ],
   "source": [
    "img,gray=get_cut_480p('4-knee.jpg')\n",
    "display(img)\n",
    "it_vote=200\n",
    "lvote=[it_vote]\n",
    "lln=[]\n",
    "mu=.45\n",
    "n_lines=2\n",
    "for x in range(0,20):\n",
    "    ln=hough_trans(img1,gray,vote=int(it_vote),can_min=200,can_max=250)\n",
    "    lln.append(ln)\n",
    "    fixed=n_lines-ln\n",
    "    #iterate\n",
    "    it_vote=it_vote-mu*fixed\n",
    "    lvote.append(it_vote)\n",
    "ln=hough_trans(img1,gray,vote=int(it_vote),can_min=200,can_max=250,plot_canny=1,plot_img=1)\n",
    "print(lvote)\n",
    "plt.figure(1)\n",
    "plt.plot(lvote)\n",
    "plt.ylabel('Vote')\n",
    "plt.xlabel('Iteration')\n",
    "plt.figure(2)\n",
    "plt.plot(lln)\n",
    "plt.ylabel('Number of lines')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#circles\n",
    "img,gray=get_480p('1-a.jpg')\n",
    "display(gray)\n",
    "blur = cv2.medianBlur(gray,5)\n",
    "display(blur)\n",
    "circles = cv2.HoughCircles(blur,3,30,3)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(gray,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    # draw the center of the circle\n",
    "    cv2.circle(gray,(i[0],i[1]),2,(0,0,255),3)\n",
    "display(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get low image resolution or take midsection of high res.\n",
    "#blur, use the bit operator to only output where the sidewalk is, travel on right side.\n",
    "#in forest area use the high intensity light as a sign of the sidewalk being there\n",
    "#perhaps make algorithim to detect white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#try to use the averaging filters to get the whole concrete slab\n",
    "img,gray=get_480p('8.jpg')\n",
    "blur = cv2.blur(gray,(2,2))\n",
    "display(blur)\n",
    "hough_trans(img,gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use bilateral filtering to remove texture(concrete) but is cpu intensive. \n",
    "img,gray=get_480p('8.jpg')\n",
    "blur = cv2.bilateralFilter(gray,9,75,75)\n",
    "display(blur)\n",
    "hough_trans(img,gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#individual colors\n",
    "img,gray=get_480p('4-knee.jpg')\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "lower_blue = np.array([50,50,110])\n",
    "upper_blue = np.array([255,255,130])\n",
    "mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    " # Bitwise-AND mask and original image\n",
    "res = cv2.bitwise_and(img,img, mask= mask)\n",
    "display(img)\n",
    "display(mask)\n",
    "display(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img=cv2.imread('4-knee.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#returns (height, width, pixel element number)\n",
    "height, width, pixel=img.shape\n",
    "print img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img2 = img[280:340, 330:390]#take section of the picture\n",
    "img[273:333, 100:160] = img2#put that section on original picutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b,g,r = cv2.split(img)#full splitting into colors\n",
    "b = img[:,:,0]#individual blue color\n",
    "imgplot = plt.imshow(b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grayscale\n",
    "gray_img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "imgplot = plt.imshow(gray_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HSV\n",
    "hsv_img=cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "imgplot = plt.imshow(hsv_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print img[0,0]\n",
    "print gray_img[0,0]\n",
    "print hsv_img[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#capture video\n",
    "cap = cv2.VideoCapture(0)\n",
    "while 1:\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:#check if cap.read() returned frame\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        display(gray)\n",
    "        #image recognition code here\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#canny edge detection\n",
    "img = cv2.imread('4-knee.jpg',0)\n",
    "edges = cv2.Canny(img,100,200)\n",
    "\n",
    "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('1-a.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,160,300,apertureSize = 3)\n",
    "lines = cv2.HoughLines(edges,1,np.pi/180,200)\n",
    "#print lines\n",
    "for rho,theta in lines[0]:\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "\n",
    "plt.subplot(121),plt.imshow(edges,cmap = 'gray')\n",
    "plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "#plt.imshow(img,cmap='gray')\n",
    "plt.show()\n",
    "#cv2.imwrite('houghlines1.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hough that uses less test points, less computations\n",
    "img = cv2.imread('4-knee.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "minLineLength = 100\n",
    "maxLineGap = 20\n",
    "lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength,maxLineGap)\n",
    "#print lines\n",
    "for x1,y1,x2,y2 in lines[0]:\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "plt.subplot(121),plt.imshow(edges,cmap = 'gray')\n",
    "plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "plt.show()\n",
    "#cv2.imwrite('houghlines2.jpg',img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
