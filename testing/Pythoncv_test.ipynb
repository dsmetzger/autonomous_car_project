{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#idk diference between cv and cv2. I think cv2 has class functionality\n",
    "#import cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#library needed on beaglebone\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "#import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_480p(file):\n",
    "    img=cv2.imread(file)\n",
    "    img=cv2.resize(img,(640,480))\n",
    "    gray_img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img,gray_img\n",
    "def get_cut_480p(file,xcut=[0,640],ycut=[0,480]):\n",
    "    img=cv2.imread(file)\n",
    "    img=cv2.resize(img,(640,480))\n",
    "    img1=img[ycut[0]:ycut[1],xcut[0]:xcut[1]]\n",
    "    gray_img=cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    return img,img1,gray_img\n",
    "def get_360p(file):\n",
    "    img=cv2.imread(file)\n",
    "    img=cv2.resize(img,(320,240))\n",
    "    gray_img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img,gray_img\n",
    "def display(img):\n",
    "    try:\n",
    "        b,g,r = cv2.split(img)\n",
    "        img2 = cv2.merge([b,g,r])\n",
    "        imgplot = plt.imshow(img)\n",
    "        plt.show()\n",
    "    except:    \n",
    "        imgplot = plt.imshow(img,cmap='gray')\n",
    "        plt.show()\n",
    "def hough_trans(img,gray,can_min=50,can_max=350,vote=100,plot_canny=0,plot_img=0):\n",
    "    t1 = time.time()\n",
    "    edges = cv2.Canny(gray,can_min,can_max,apertureSize = 3)\n",
    "    t2 = time.time()\n",
    "    lines = cv2.HoughLines(edges,1,np.pi/180,vote)\n",
    "    t3 = time.time()\n",
    "    print 'canny',t2 - t1\n",
    "    print 'hough',t3 - t2\n",
    "    if plot_canny==1:\n",
    "                display(edges)\n",
    "    #print lines\n",
    "    if plot_img==1:\n",
    "        try:\n",
    "            for rho,theta in lines[0]:\n",
    "                print rho,theta\n",
    "                a = np.cos(theta)\n",
    "                b = np.sin(theta)\n",
    "                x0 = a*rho\n",
    "                y0 = b*rho\n",
    "                x1 = int(x0 + 1000*(-b))\n",
    "                y1 = int(y0 + 1000*(a))\n",
    "                x2 = int(x0 - 1000*(-b))\n",
    "                y2 = int(y0 - 1000*(a))\n",
    "                cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "            display(img)\n",
    "        except:\n",
    "            print('could not plot')\n",
    "    else:\n",
    "        try:\n",
    "            return len(lines[0])\n",
    "        except:\n",
    "            return 0\n",
    "def hough_transp(img,gray,can_min=150,can_max=300,vote=150,\n",
    "                 minLineLength = 20,maxLineGap = 15,plot_canny=0,plot_img=0):\n",
    "    #hough that uses less test points, less computations\n",
    "    t1 = time.time()\n",
    "    edges = cv2.Canny(gray,can_min,can_max,apertureSize = 3)\n",
    "    t2 = time.time()\n",
    "    lines = cv2.HoughLinesP(edges,1,np.pi/180,vote,minLineLength,maxLineGap)\n",
    "    t3 = time.time()\n",
    "    print 'canny',t2 - t1\n",
    "    print 'hough',t3 - t2\n",
    "    if plot_canny==1:\n",
    "        display(edges)\n",
    "    #print lines\n",
    "    if plot_img==1:\n",
    "        try:\n",
    "            for x1,y1,x2,y2 in lines[0]:\n",
    "                cv2.line(img,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "            display(img)\n",
    "        except:\n",
    "            print('could not plot')\n",
    "    else:\n",
    "        try:\n",
    "            return len(lines[0])\n",
    "        except:\n",
    "            return 0\n",
    "def hough_trans_blur(img,gray,can_min=50,can_max=350,vote=100,plot_canny=0):\n",
    "    t1 = time.time()\n",
    "    blur = cv2.blur(gray,(2,2))\n",
    "    t2 = time.time()\n",
    "    edges = cv2.Canny(gray,can_min,can_max,apertureSize = 3)\n",
    "    t3 = time.time()\n",
    "    lines = cv2.HoughLines(edges,1,np.pi/180,vote)\n",
    "    t4 = time.time()\n",
    "    print 'blur', t2 - t1\n",
    "    print 'canny',t3 - t2\n",
    "    print 'hough',t4 - t3\n",
    "    #print lines\n",
    "    for rho,theta in lines[0]:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*rho\n",
    "        y0 = b*rho\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "        cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "    if plot_canny==1:\n",
    "        display(edges)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wh_det(img,x1=10,x2=630,y1=470,y2=0,xit=10,yit=-10,slope_en=1,er_max=3):    \n",
    "    #create green pointers on sidewalk\n",
    "    count=[]\n",
    "    tot=0\n",
    "    for x in range(x1,x2,xit):\n",
    "        test=er_max#used to ignore noise in the image. if the values goes too low the system stops incrementing in that y direction\n",
    "        for y in range(y1,y2,yit):\n",
    "            bgr=img[y,x]\n",
    "            if abs(int(bgr[1])-int(bgr[2]))<14 and ((int(bgr[0])*1.25)>(int(bgr[1])+int(bgr[2]))/2):#works\n",
    "                tot+=1\n",
    "                if test<er_max:\n",
    "                    test+=1\n",
    "                #draw where true\n",
    "                for xn in range(-2,3):\n",
    "                    for yn in range(-2,3):\n",
    "                        img[y+yn,x+xn]=[0,200,255]\n",
    "            else:\n",
    "                test-=1\n",
    "                if test<1:\n",
    "                    break\n",
    "        count.append(tot)\n",
    "        tot=0\n",
    "    #calculate slope,\n",
    "    slopes=[]\n",
    "    c1=yit/xit\n",
    "    print len(count)\n",
    "    if slope_en==1:\n",
    "        slopes=[]\n",
    "        for x1 in range(0,len(count)-1):\n",
    "            slopes.append(float(count[x1]-count[x1+1])*c1)   \n",
    "    #print results\n",
    "    print count\n",
    "    print slopes\n",
    "    display(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "[37, 39, 38, 38, 38, 38, 39, 38, 38, 39, 39, 39, 39, 39, 39, 38, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 38, 37, 38, 38, 38, 38, 38, 37, 37, 38, 37, 37, 37, 37, 37, 36, 36, 36, 36]\n",
      "[2.0, -1.0, -0.0, -0.0, -0.0, 1.0, -1.0, -0.0, 1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -1.0, 1.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -1.0, -1.0, 1.0, -0.0, -0.0, -0.0, -0.0, -1.0, -0.0, 1.0, -1.0, -0.0, -0.0, -0.0, -0.0, -1.0, -0.0, -0.0, -0.0]\n"
     ]
    }
   ],
   "source": [
    "img,gray=get_360p('debug_img9.jpg')\n",
    "wh_det(img,x1=0,x2=320,y1=230,y2=30,xit=5, yit=-5,er_max=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def control_distance(slopes,xit,yit,gain,l1,side=1,dist=40):#side=1, right of sidewalk\n",
    "\tif side==1:\n",
    "\t\t#find sidewalk edge\n",
    "\t\tzeroend=len(l1)-1\n",
    "\t\tfor x in range(len(l1)/2, len(l1)):\n",
    "\t\t\tif l1[x]==0:\n",
    "\t\t\t\tzeroend=x\n",
    "\t\t\t\tbreak\n",
    "\t\t#offset from slope, positive for turn right\n",
    "\t\tit=0\n",
    "\t\ttot=0\n",
    "\t\tfor x in range(zeroend-5, zeroend-1):\n",
    "\t\t\tif slopes[x]!=0:\n",
    "\t\t\t\ttot+=slopes[x]\n",
    "\t\t\t\tit+=1\n",
    "\t\tif it==0:\n",
    "\t\t\treturn 20\n",
    "\t\tslope=tot/it\n",
    "\t\tb=l1[zeroend]*yit-slope*zeroend*xit\n",
    "\t\tdist_to_sw=(-b)/slope\n",
    "\t\tprint 'distance to sidewalk, '+str(dist_to_sw)+' pixels'\n",
    "\t\toffset=gain*(dist_to_sw-dist)\n",
    "\t\tif offset>20:\n",
    "\t\t\treturn 20\n",
    "\t\telif offset<-20:\n",
    "\t\t\treturn -20\n",
    "\t\telse:\n",
    "\t\t\treturn offset\n",
    "\telse:\n",
    "\t\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance to sidewalk, 495.0 pixels\n",
      "-5.0\n"
     ]
    }
   ],
   "source": [
    "l1=[37, 39, 38, 38, 38, 38, 39, 38, 38, 39, 39, 39, 39, 39, 39, 38, 39, 39, 39, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 39, 38, 37, 38, 38, 38, 38, 38, 37, 37, 38, 37, 37, 37, 37, 37, 36, 36, 36, 36]\n",
    "slopes=[2.0, -1.0, -0.0, -0.0, -0.0, 1.0, -1.0, -0.0, 1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -1.0, 1.0, -0.0, -0.0, 1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -1.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -1.0, -1.0, 1.0, -0.0, -0.0, -0.0, -0.0, -1.0, -0.0, 1.0, -1.0, -0.0, -0.0, -0.0, -0.0, -1.0, -0.0, -0.0, -0.0]\n",
    "print control_distance(slopes,5,5,1,l1,dist=500)#,side=1,dist=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for x in range(10,310,5):\n",
    "        for y in range(235,200,5):\n",
    "            bgr=img[y,x]\n",
    "            if abs(int(bgr[1])-int(bgr[2]))<14 and ((bgr[0]*1.25)>(bgr[1]+bgr[2])/2):\n",
    "                print '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n",
      "[74, 74, 71, 73, 73, 74, 68, 72, 73, 72, 74, 74, 74, 73, 74, 74, 74, 74, 73, 74, 70, 74, 73, 74, 74, 73, 74, 74, 74, 74, 74, 73, 74, 73, 73, 72, 72, 72, 72, 73, 73, 73, 74, 74, 72, 71, 70, 71, 70, 69, 70, 70, 70, 70, 70, 69, 68, 73, 70, 67, 73, 73, 72, 74, 73, 74, 74, 73, 72, 71, 71, 71, 74, 74, 72, 74, 73, 73, 73, 74, 74, 72, 74, 73, 72, 70, 73, 73, 73, 71, 35, 28, 23, 20, 18, 15, 16, 12, 11, 10, 7, 0, 0, 1, 2, 0, 0, 0, 2, 4, 1, 3, 1, 1, 0, 1, 2, 0, 2, 0, 1, 0, 0, 0, 0, 0]\n",
      "[0.0, 1.2, 0.0, 0.2, 0.0, -0.4, 0.2, -0.6, 0.0, -0.6, 0.2, -0.6, -0.2, 0.0, -0.2, -4.0, -3.2, 0.0, -0.2, 0.0, -0.2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:9: RuntimeWarning: overflow encountered in ubyte_scalars\n"
     ]
    }
   ],
   "source": [
    "img,gray=get_480p('pics/1.jpg')\n",
    "wh_det(img,x1=5,x2=635,y1=475,y2=105,xit=5,yit=-5,er_max=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126\n",
      "[62, 62, 64, 62, 62, 61, 63, 63, 62, 59, 64, 61, 60, 61, 61, 61, 64, 64, 62, 64, 63, 63, 65, 66, 65, 65, 72, 71, 70, 71, 71, 71, 71, 72, 68, 68, 68, 68, 69, 69, 70, 69, 69, 73, 73, 70, 70, 71, 71, 72, 72, 72, 72, 73, 74, 74, 74, 74, 74, 74, 74, 74, 74, 71, 71, 71, 71, 65, 62, 60, 57, 54, 51, 47, 45, 44, 42, 39, 33, 30, 24, 23, 21, 20, 23, 20, 20, 16, 16, 13, 11, 8, 5, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[-0.2, -0.4, 0.8, 0.8, 1.2, -0.6, 0.2, 0.4, 0.4, 0.0, -0.6, -3.4, -2.4, -2.6, -2.0, -2.2, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:9: RuntimeWarning: overflow encountered in ubyte_scalars\n"
     ]
    }
   ],
   "source": [
    "img,gray=get_480p('pics/2.jpg')\n",
    "wh_det(img,x1=5,x2=635,y1=475,y2=105,xit=5,yit=-5,er_max=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#capture video\n",
    "cap = cv2.VideoCapture(1)\n",
    "while 1:\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:#check if cap.read() returned frame\n",
    "        display(frame)\n",
    "        #image recognition code here\n",
    "        cv2.imwrite('pseye_3.jpg', frame)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(frame[10,10][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 24, 23, 23, 23, 24, 24, 23, 23, 25, 24, 24, 23, 25, 26, 25, 24, 23, 24, 24, 25, 24, 24, 23, 23, 23, 23, 23, 25, 23, 23, 23, 23, 24, 23, 24, 23, 23, 23, 23, 23, 23, 23, 23, 23, 22, 22, 24, 24, 25, 22, 23, 22, 22, 22, 23, 22, 22, 23]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:9: RuntimeWarning: overflow encountered in ubyte_scalars\n"
     ]
    }
   ],
   "source": [
    "img,gray=get_480p('pseye_1.jpg')\n",
    "wh_det(img,x1=30,x2=620,y1=470,y2=100,xit=10,yit=-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#playing video\n",
    "cap = cv2.VideoCapture('output.avi')\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    display(frame)\n",
    "    break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[134 124 117]\n",
      "  [107  97  90]\n",
      "  [114 104  97]\n",
      "  ..., \n",
      "  [111 102  95]\n",
      "  [111 103  99]\n",
      "  [113 104 100]]\n",
      "\n",
      " [[118 108 101]\n",
      "  [112 102  95]\n",
      "  [115 105  98]\n",
      "  ..., \n",
      "  [125 116 109]\n",
      "  [117 109 102]\n",
      "  [118 110 103]]\n",
      "\n",
      " [[115 105  98]\n",
      "  [117 107 100]\n",
      "  [126 116 109]\n",
      "  ..., \n",
      "  [116 108 101]\n",
      "  [113 106  98]\n",
      "  [122 114 107]]\n",
      "\n",
      " ..., \n",
      " [[120 114 107]\n",
      "  [122 116 111]\n",
      "  [112 106 101]\n",
      "  ..., \n",
      "  [104  96  90]\n",
      "  [108  99  95]\n",
      "  [105  96  92]]\n",
      "\n",
      " [[118 112 107]\n",
      "  [123 117 112]\n",
      "  [129 123 118]\n",
      "  ..., \n",
      "  [111 102  97]\n",
      "  [106  97  93]\n",
      "  [106  97  93]]\n",
      "\n",
      " [[114 108 103]\n",
      "  [119 113 108]\n",
      "  [118 112 107]\n",
      "  ..., \n",
      "  [109 101  95]\n",
      "  [105  96  92]\n",
      "  [106  97  93]]]\n"
     ]
    }
   ],
   "source": [
    "#look at white concrete\n",
    "img,reimg,gray=get_cut_480p('9.jpg',xcut=[400,470],ycut=[420,480])#get img, roi image, and gray cut img\n",
    "#img,reimg,gray=get_cut_480p('1.jpg',xcut=[600,640],ycut=[400,480])#get img, roi image, and gray cut img\n",
    "display(reimg)\n",
    "b,g,r = cv2.split(reimg)\n",
    "print reimg\n",
    "#hsv to detect white?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:25: RuntimeWarning: overflow encountered in ubyte_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version=2\n",
    "image='pseye_1'\n",
    "#create green pointers on sidewalk\n",
    "img,reimg,gray=get_cut_480p(image+'.jpg',xcut=[0,640],ycut=[0,480])#get img, roi image, and gray cut img\n",
    "#display(reimg)\n",
    "#b,g,r = cv2.split(reimg)\n",
    "i=0;\n",
    "\n",
    "#get from movie\n",
    "#cap = cv2.VideoCapture('output.avi')\n",
    "#ret, reimg = cap.read()\n",
    "        \n",
    "for x in range(0,640,10):\n",
    "    for y in range(0,480,10):\n",
    "        bgr=reimg[y,x]\n",
    "        #also take the difference between g and r? if too high means its not white.\n",
    "        if version==1:\n",
    "            if bgr[0]*1.25>(bgr[1]+bgr[2])/2:#check if white with a bit more of blue    works\n",
    "                i+=1\n",
    "                #draw where true\n",
    "                for x1 in range(-2,3):\n",
    "                    for y1 in range(-2,3):\n",
    "                        reimg[y+y1,x+x1]=[0,200,255]\n",
    "        else:    \n",
    "            if abs(int(bgr[1])-int(bgr[2]))<14 and ((bgr[0]*1.25)>(bgr[1]+bgr[2])/2):#works\n",
    "                i+=1\n",
    "                #draw where true\n",
    "                for x1 in range(-2,3):\n",
    "                    for y1 in range(-2,3):\n",
    "                        reimg[y+y1,x+x1]=[0,200,255]\n",
    "print i\n",
    "#hsv to detect white?\n",
    "display(reimg)\n",
    "cv2.imwrite(image+'_white_detection_v'+str(version)+'.jpg', reimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#debug white detection\n",
    "#print reimg[350:480,220:380]\n",
    "bgr=reimg[360,240]\n",
    "print 1.2*bgr[1],bgr[1]\n",
    "print abs(int(bgr[1])-int(bgr[2]))\n",
    "if (abs(bgr[1]-bgr[2])<100) and ((bgr[0]*1.2)>(bgr[1]+bgr[2])/2):\n",
    "    display(reimg[350:480,220:380])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find corners\n",
    "img,gray=get_480p('1.jpg')\n",
    "\n",
    "#gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "\n",
    "#result is dilated for marking the corners, not important\n",
    "dst = cv2.dilate(dst,None)\n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img[dst>0.01*dst.max()]=[0,0,255]\n",
    "\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img1,gray=get_480p('2-knee.jpg')\n",
    "display(img1)\n",
    "#blur = cv2.bilateralFilter(gray,9,75,75)\n",
    "#display(blur)\n",
    "hough_trans(img1,gray,vote=220,can_min=150,can_max=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#iterating hough\n",
    "img,reimg,gray=get_cut_480p('1.jpg',xcut=[240,520],ycut=[200,480])#get img, roi image, and gray cut img\n",
    "display(reimg)\n",
    "#img1,gray=get_360p('2-knee.jpg')\n",
    "it_vote=100\n",
    "lvote=[it_vote]\n",
    "lln=[]\n",
    "mu=.75\n",
    "n_lines=5\n",
    "for x in range(0,5):\n",
    "    ln=hough_trans(reimg,gray,vote=int(it_vote),can_min=200,can_max=250)\n",
    "    lln.append(ln)\n",
    "    fixed=n_lines-ln\n",
    "    #iterate\n",
    "    it_vote=it_vote-mu*fixed\n",
    "    lvote.append(it_vote)\n",
    "ln=hough_trans(reimg,gray,vote=int(it_vote),can_min=200,can_max=250,plot_canny=1,plot_img=1)\n",
    "print(lvote)\n",
    "plt.figure(1)\n",
    "plt.plot(lvote)\n",
    "plt.ylabel('Vote')\n",
    "plt.xlabel('Iteration')\n",
    "plt.figure(2)\n",
    "plt.plot(lln)\n",
    "plt.ylabel('Number of lines')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img,gray=get_cut_480p('4-knee.jpg')\n",
    "display(img)\n",
    "it_vote=200\n",
    "lvote=[it_vote]\n",
    "lln=[]\n",
    "mu=.45\n",
    "n_lines=2\n",
    "for x in range(0,20):\n",
    "    ln=hough_trans(img1,gray,vote=int(it_vote),can_min=200,can_max=250)\n",
    "    lln.append(ln)\n",
    "    fixed=n_lines-ln\n",
    "    #iterate\n",
    "    it_vote=it_vote-mu*fixed\n",
    "    lvote.append(it_vote)\n",
    "ln=hough_trans(img1,gray,vote=int(it_vote),can_min=200,can_max=250,plot_canny=1,plot_img=1)\n",
    "print(lvote)\n",
    "plt.figure(1)\n",
    "plt.plot(lvote)\n",
    "plt.ylabel('Vote')\n",
    "plt.xlabel('Iteration')\n",
    "plt.figure(2)\n",
    "plt.plot(lln)\n",
    "plt.ylabel('Number of lines')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#circles\n",
    "img,gray=get_480p('1-a.jpg')\n",
    "display(gray)\n",
    "blur = cv2.medianBlur(gray,5)\n",
    "display(blur)\n",
    "circles = cv2.HoughCircles(blur,3,30,3)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(gray,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    # draw the center of the circle\n",
    "    cv2.circle(gray,(i[0],i[1]),2,(0,0,255),3)\n",
    "display(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get low image resolution or take midsection of high res.\n",
    "#blur, use the bit operator to only output where the sidewalk is, travel on right side.\n",
    "#in forest area use the high intensity light as a sign of the sidewalk being there\n",
    "#perhaps make algorithim to detect white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#try to use the averaging filters to get the whole concrete slab\n",
    "img,gray=get_480p('8.jpg')\n",
    "blur = cv2.blur(gray,(2,2))\n",
    "display(blur)\n",
    "hough_trans(img,gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use bilateral filtering to remove texture(concrete) but is cpu intensive. \n",
    "img,gray=get_480p('8.jpg')\n",
    "blur = cv2.bilateralFilter(gray,9,75,75)\n",
    "display(blur)\n",
    "hough_trans(img,gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#individual colors\n",
    "img,gray=get_480p('4-knee.jpg')\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "lower_blue = np.array([50,50,110])\n",
    "upper_blue = np.array([255,255,130])\n",
    "mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    " # Bitwise-AND mask and original image\n",
    "res = cv2.bitwise_and(img,img, mask= mask)\n",
    "display(img)\n",
    "display(mask)\n",
    "display(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img=cv2.imread('4-knee.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#returns (height, width, pixel element number)\n",
    "height, width, pixel=img.shape\n",
    "print img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img2 = img[280:340, 330:390]#take section of the picture\n",
    "img[273:333, 100:160] = img2#put that section on original picutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b,g,r = cv2.split(img)#full splitting into colors\n",
    "b = img[:,:,0]#individual blue color\n",
    "imgplot = plt.imshow(b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grayscale\n",
    "gray_img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "imgplot = plt.imshow(gray_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HSV\n",
    "hsv_img=cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "imgplot = plt.imshow(hsv_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print img[0,0]\n",
    "print gray_img[0,0]\n",
    "print hsv_img[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#canny edge detection\n",
    "img = cv2.imread('4-knee.jpg',0)\n",
    "edges = cv2.Canny(img,100,200)\n",
    "\n",
    "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('1-a.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,160,300,apertureSize = 3)\n",
    "lines = cv2.HoughLines(edges,1,np.pi/180,200)\n",
    "#print lines\n",
    "for rho,theta in lines[0]:\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "\n",
    "plt.subplot(121),plt.imshow(edges,cmap = 'gray')\n",
    "plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "#plt.imshow(img,cmap='gray')\n",
    "plt.show()\n",
    "#cv2.imwrite('houghlines1.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hough that uses less test points, less computations\n",
    "img = cv2.imread('4-knee.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "minLineLength = 100\n",
    "maxLineGap = 20\n",
    "lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength,maxLineGap)\n",
    "#print lines\n",
    "for x1,y1,x2,y2 in lines[0]:\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "plt.subplot(121),plt.imshow(edges,cmap = 'gray')\n",
    "plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "plt.show()\n",
    "#cv2.imwrite('houghlines2.jpg',img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
