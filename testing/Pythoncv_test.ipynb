{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#idk diference between cv and cv2. I think cv2 has class functionality\n",
    "#import cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#library needed on beaglebone\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "#import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_480p(file):\n",
    "    img=cv2.imread(file)\n",
    "    img=cv2.resize(img,(640,480))\n",
    "    gray_img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img,gray_img\n",
    "def get_cut_480p(file,xcut=[0,640],ycut=[0,480]):\n",
    "    img=cv2.imread(file)\n",
    "    img=cv2.resize(img,(640,480))\n",
    "    img1=img[ycut[0]:ycut[1],xcut[0]:xcut[1]]\n",
    "    gray_img=cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    return img,img1,gray_img\n",
    "def get_360p(file):\n",
    "    img=cv2.imread(file)\n",
    "    img=cv2.resize(img,(320,240))\n",
    "    gray_img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return img,gray_img\n",
    "def display(img):\n",
    "    try:\n",
    "        b,g,r = cv2.split(img)\n",
    "        img2 = cv2.merge([b,g,r])\n",
    "        imgplot = plt.imshow(img)\n",
    "        plt.show()\n",
    "    except:    \n",
    "        imgplot = plt.imshow(img,cmap='gray')\n",
    "        plt.show()\n",
    "def hough_trans(img,gray,can_min=50,can_max=350,vote=100,plot_canny=0,plot_img=0):\n",
    "    t1 = time.time()\n",
    "    edges = cv2.Canny(gray,can_min,can_max,apertureSize = 3)\n",
    "    t2 = time.time()\n",
    "    lines = cv2.HoughLines(edges,1,np.pi/180,vote)\n",
    "    t3 = time.time()\n",
    "    print 'canny',t2 - t1\n",
    "    print 'hough',t3 - t2\n",
    "    if plot_canny==1:\n",
    "                display(edges)\n",
    "    #print lines\n",
    "    if plot_img==1:\n",
    "        try:\n",
    "            for rho,theta in lines[0]:\n",
    "                print rho,theta\n",
    "                a = np.cos(theta)\n",
    "                b = np.sin(theta)\n",
    "                x0 = a*rho\n",
    "                y0 = b*rho\n",
    "                x1 = int(x0 + 1000*(-b))\n",
    "                y1 = int(y0 + 1000*(a))\n",
    "                x2 = int(x0 - 1000*(-b))\n",
    "                y2 = int(y0 - 1000*(a))\n",
    "                cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "            display(img)\n",
    "        except:\n",
    "            print('could not plot')\n",
    "    else:\n",
    "        try:\n",
    "            return len(lines[0])\n",
    "        except:\n",
    "            return 0\n",
    "def hough_transp(img,gray,can_min=150,can_max=300,vote=150,\n",
    "                 minLineLength = 20,maxLineGap = 15,plot_canny=0,plot_img=0):\n",
    "    #hough that uses less test points, less computations\n",
    "    t1 = time.time()\n",
    "    edges = cv2.Canny(gray,can_min,can_max,apertureSize = 3)\n",
    "    t2 = time.time()\n",
    "    lines = cv2.HoughLinesP(edges,1,np.pi/180,vote,minLineLength,maxLineGap)\n",
    "    t3 = time.time()\n",
    "    print 'canny',t2 - t1\n",
    "    print 'hough',t3 - t2\n",
    "    if plot_canny==1:\n",
    "        display(edges)\n",
    "    #print lines\n",
    "    if plot_img==1:\n",
    "        try:\n",
    "            for x1,y1,x2,y2 in lines[0]:\n",
    "                cv2.line(img,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "            display(img)\n",
    "        except:\n",
    "            print('could not plot')\n",
    "    else:\n",
    "        try:\n",
    "            return len(lines[0])\n",
    "        except:\n",
    "            return 0\n",
    "def hough_trans_blur(img,gray,can_min=50,can_max=350,vote=100,plot_canny=0):\n",
    "    t1 = time.time()\n",
    "    blur = cv2.blur(gray,(2,2))\n",
    "    t2 = time.time()\n",
    "    edges = cv2.Canny(gray,can_min,can_max,apertureSize = 3)\n",
    "    t3 = time.time()\n",
    "    lines = cv2.HoughLines(edges,1,np.pi/180,vote)\n",
    "    t4 = time.time()\n",
    "    print 'blur', t2 - t1\n",
    "    print 'canny',t3 - t2\n",
    "    print 'hough',t4 - t3\n",
    "    #print lines\n",
    "    for rho,theta in lines[0]:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a*rho\n",
    "        y0 = b*rho\n",
    "        x1 = int(x0 + 1000*(-b))\n",
    "        y1 = int(y0 + 1000*(a))\n",
    "        x2 = int(x0 - 1000*(-b))\n",
    "        y2 = int(y0 - 1000*(a))\n",
    "        cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "    if plot_canny==1:\n",
    "        display(edges)\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#capture video\n",
    "cap = cv2.VideoCapture(1)\n",
    "while 1:\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:#check if cap.read() returned frame\n",
    "        display(frame)\n",
    "        #image recognition code here\n",
    "        cv2.imwrite('pseye_2.jpg', frame)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#playing video\n",
    "cap = cv2.VideoCapture('output.avi')\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    display(frame)\n",
    "    break\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#look at white concrete\n",
    "img,reimg,gray=get_cut_480p('9.jpg',xcut=[400,470],ycut=[420,480])#get img, roi image, and gray cut img\n",
    "#img,reimg,gray=get_cut_480p('1.jpg',xcut=[600,640],ycut=[400,480])#get img, roi image, and gray cut img\n",
    "display(reimg)\n",
    "b,g,r = cv2.split(reimg)\n",
    "print reimg\n",
    "#hsv to detect white?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:25: RuntimeWarning: overflow encountered in ubyte_scalars\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version=2\n",
    "image='pseye_1'\n",
    "#create green pointers on sidewalk\n",
    "img,reimg,gray=get_cut_480p(image+'.jpg',xcut=[0,640],ycut=[0,480])#get img, roi image, and gray cut img\n",
    "#display(reimg)\n",
    "#b,g,r = cv2.split(reimg)\n",
    "i=0;\n",
    "\n",
    "#get from movie\n",
    "#cap = cv2.VideoCapture('output.avi')\n",
    "#ret, reimg = cap.read()\n",
    "        \n",
    "for x in range(0,640,10):\n",
    "    for y in range(0,480,10):\n",
    "        bgr=reimg[y,x]\n",
    "        #also take the difference between g and r? if too high means its not white.\n",
    "        if version==1:\n",
    "            if bgr[0]*1.25>(bgr[1]+bgr[2])/2:#check if white with a bit more of blue    works\n",
    "                i+=1\n",
    "                #draw where true\n",
    "                for x1 in range(-2,3):\n",
    "                    for y1 in range(-2,3):\n",
    "                        reimg[y+y1,x+x1]=[0,200,255]\n",
    "        else:    \n",
    "            if abs(int(bgr[1])-int(bgr[2]))<14 and ((bgr[0]*1.25)>(bgr[1]+bgr[2])/2):#works\n",
    "                i+=1\n",
    "                #draw where true\n",
    "                for x1 in range(-2,3):\n",
    "                    for y1 in range(-2,3):\n",
    "                        reimg[y+y1,x+x1]=[0,200,255]\n",
    "print i\n",
    "#hsv to detect white?\n",
    "display(reimg)\n",
    "cv2.imwrite(image+'_white_detection_v'+str(version)+'.jpg', reimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#debug white detection\n",
    "#print reimg[350:480,220:380]\n",
    "bgr=reimg[360,240]\n",
    "print 1.2*bgr[1],bgr[1]\n",
    "print abs(int(bgr[1])-int(bgr[2]))\n",
    "if (abs(bgr[1]-bgr[2])<100) and ((bgr[0]*1.2)>(bgr[1]+bgr[2])/2):\n",
    "    display(reimg[350:480,220:380])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#find corners\n",
    "img,gray=get_480p('1.jpg')\n",
    "\n",
    "#gray = np.float32(gray)\n",
    "dst = cv2.cornerHarris(gray,2,3,0.04)\n",
    "\n",
    "#result is dilated for marking the corners, not important\n",
    "dst = cv2.dilate(dst,None)\n",
    "\n",
    "# Threshold for an optimal value, it may vary depending on the image.\n",
    "img[dst>0.01*dst.max()]=[0,0,255]\n",
    "\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img1,gray=get_480p('2-knee.jpg')\n",
    "display(img1)\n",
    "#blur = cv2.bilateralFilter(gray,9,75,75)\n",
    "#display(blur)\n",
    "hough_trans(img1,gray,vote=220,can_min=150,can_max=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#iterating hough\n",
    "img,reimg,gray=get_cut_480p('1.jpg',xcut=[240,520],ycut=[200,480])#get img, roi image, and gray cut img\n",
    "display(reimg)\n",
    "#img1,gray=get_360p('2-knee.jpg')\n",
    "it_vote=100\n",
    "lvote=[it_vote]\n",
    "lln=[]\n",
    "mu=.75\n",
    "n_lines=5\n",
    "for x in range(0,5):\n",
    "    ln=hough_trans(reimg,gray,vote=int(it_vote),can_min=200,can_max=250)\n",
    "    lln.append(ln)\n",
    "    fixed=n_lines-ln\n",
    "    #iterate\n",
    "    it_vote=it_vote-mu*fixed\n",
    "    lvote.append(it_vote)\n",
    "ln=hough_trans(reimg,gray,vote=int(it_vote),can_min=200,can_max=250,plot_canny=1,plot_img=1)\n",
    "print(lvote)\n",
    "plt.figure(1)\n",
    "plt.plot(lvote)\n",
    "plt.ylabel('Vote')\n",
    "plt.xlabel('Iteration')\n",
    "plt.figure(2)\n",
    "plt.plot(lln)\n",
    "plt.ylabel('Number of lines')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img,gray=get_cut_480p('4-knee.jpg')\n",
    "display(img)\n",
    "it_vote=200\n",
    "lvote=[it_vote]\n",
    "lln=[]\n",
    "mu=.45\n",
    "n_lines=2\n",
    "for x in range(0,20):\n",
    "    ln=hough_trans(img1,gray,vote=int(it_vote),can_min=200,can_max=250)\n",
    "    lln.append(ln)\n",
    "    fixed=n_lines-ln\n",
    "    #iterate\n",
    "    it_vote=it_vote-mu*fixed\n",
    "    lvote.append(it_vote)\n",
    "ln=hough_trans(img1,gray,vote=int(it_vote),can_min=200,can_max=250,plot_canny=1,plot_img=1)\n",
    "print(lvote)\n",
    "plt.figure(1)\n",
    "plt.plot(lvote)\n",
    "plt.ylabel('Vote')\n",
    "plt.xlabel('Iteration')\n",
    "plt.figure(2)\n",
    "plt.plot(lln)\n",
    "plt.ylabel('Number of lines')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#circles\n",
    "img,gray=get_480p('1-a.jpg')\n",
    "display(gray)\n",
    "blur = cv2.medianBlur(gray,5)\n",
    "display(blur)\n",
    "circles = cv2.HoughCircles(blur,3,30,3)\n",
    "\n",
    "circles = np.uint16(np.around(circles))\n",
    "for i in circles[0,:]:\n",
    "    # draw the outer circle\n",
    "    cv2.circle(gray,(i[0],i[1]),i[2],(0,255,0),2)\n",
    "    # draw the center of the circle\n",
    "    cv2.circle(gray,(i[0],i[1]),2,(0,0,255),3)\n",
    "display(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get low image resolution or take midsection of high res.\n",
    "#blur, use the bit operator to only output where the sidewalk is, travel on right side.\n",
    "#in forest area use the high intensity light as a sign of the sidewalk being there\n",
    "#perhaps make algorithim to detect white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#try to use the averaging filters to get the whole concrete slab\n",
    "img,gray=get_480p('8.jpg')\n",
    "blur = cv2.blur(gray,(2,2))\n",
    "display(blur)\n",
    "hough_trans(img,gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#use bilateral filtering to remove texture(concrete) but is cpu intensive. \n",
    "img,gray=get_480p('8.jpg')\n",
    "blur = cv2.bilateralFilter(gray,9,75,75)\n",
    "display(blur)\n",
    "hough_trans(img,gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#individual colors\n",
    "img,gray=get_480p('4-knee.jpg')\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "lower_blue = np.array([50,50,110])\n",
    "upper_blue = np.array([255,255,130])\n",
    "mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    " # Bitwise-AND mask and original image\n",
    "res = cv2.bitwise_and(img,img, mask= mask)\n",
    "display(img)\n",
    "display(mask)\n",
    "display(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img=cv2.imread('4-knee.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#returns (height, width, pixel element number)\n",
    "height, width, pixel=img.shape\n",
    "print img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img2 = img[280:340, 330:390]#take section of the picture\n",
    "img[273:333, 100:160] = img2#put that section on original picutre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b,g,r = cv2.split(img)#full splitting into colors\n",
    "b = img[:,:,0]#individual blue color\n",
    "imgplot = plt.imshow(b)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grayscale\n",
    "gray_img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "imgplot = plt.imshow(gray_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#HSV\n",
    "hsv_img=cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "imgplot = plt.imshow(hsv_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print img[0,0]\n",
    "print gray_img[0,0]\n",
    "print hsv_img[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#canny edge detection\n",
    "img = cv2.imread('4-knee.jpg',0)\n",
    "edges = cv2.Canny(img,100,200)\n",
    "\n",
    "plt.subplot(121),plt.imshow(img,cmap = 'gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122),plt.imshow(edges,cmap = 'gray')\n",
    "plt.title('Edge Image'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('1-a.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,160,300,apertureSize = 3)\n",
    "lines = cv2.HoughLines(edges,1,np.pi/180,200)\n",
    "#print lines\n",
    "for rho,theta in lines[0]:\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a*rho\n",
    "    y0 = b*rho\n",
    "    x1 = int(x0 + 1000*(-b))\n",
    "    y1 = int(y0 + 1000*(a))\n",
    "    x2 = int(x0 - 1000*(-b))\n",
    "    y2 = int(y0 - 1000*(a))\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "\n",
    "plt.subplot(121),plt.imshow(edges,cmap = 'gray')\n",
    "plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "#plt.imshow(img,cmap='gray')\n",
    "plt.show()\n",
    "#cv2.imwrite('houghlines1.jpg',img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#hough that uses less test points, less computations\n",
    "img = cv2.imread('4-knee.jpg')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "edges = cv2.Canny(gray,50,150,apertureSize = 3)\n",
    "minLineLength = 100\n",
    "maxLineGap = 20\n",
    "lines = cv2.HoughLinesP(edges,1,np.pi/180,100,minLineLength,maxLineGap)\n",
    "#print lines\n",
    "for x1,y1,x2,y2 in lines[0]:\n",
    "    cv2.line(img,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "plt.subplot(121),plt.imshow(edges,cmap = 'gray')\n",
    "plt.subplot(122),plt.imshow(img,cmap = 'gray')\n",
    "plt.show()\n",
    "#cv2.imwrite('houghlines2.jpg',img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
